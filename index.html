<!DOCTYPE html><html lang="en"><head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="google-site-verification" content="hOcV46lFgacSd6__Hj0Yr8lNVvo5HzYjAhb6aL8uLPU">      
      <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags
      google-site-verification=hOcV46lFgacSd6__Hj0Yr8lNVvo5HzYjAhb6aL8uLPU -->
      <title>Leroy (Lirui) Wang</title>
      <!-- Bootstrap -->
      <link href="css/bootstrap.css" rel="stylesheet">
      <link href="css/custom.css" rel="stylesheet">
      <link rel="icon" href="images/head5.jpg">    
      <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
      <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
      <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
   <style>
      hr {
      margin-top:40px;
      margin-bottom:40px;
      }
   </style><script type="text/javascript">
          function toggle_visibility(id) {
             var e = document.getElementById(id);
             if(e.style.display == 'block')
                e.style.display = 'none';
             else
                e.style.display = 'block';
          }
   </script><script>
     function switchToGifFleet() {
       document.getElementById('thumbnail_fleetmerge').src = 'fleet_mergin.gif';
     }

     // Set timeout for 1 second to switch the image
     setTimeout(switchToGifFleet, 3000);
   </script><script>
     function switchToGifPoCo() {
       document.getElementById('thumbnail_poco').src = 'policycomp.gif';
     }

     // Set timeout for 1 second to switch the image
     setTimeout(switchToGifPoCo, 3000);
   </script><script>
     function switchToGifHPT() {
       document.getElementById('thumbnail_hpt').src = 'hpt.gif';
     }

     // Set timeout for 1 second to switch the image
     setTimeout(switchToGifHPT, 3000);
   </script></head>
   
   
   
   
      
   <body>
      <div class="container">
      <div class="row">
      <div style="padding-left: 10px; padding-right: 20px">
      <div class="span3 bs-docs-sidebar">
         <!-- <hr class="hidden-phone"/> -->
         <div class="col-md-3" ,="" style="padding-right: 55px;padding-top: 95px">
            <img class="logo-image" src="images/head5.jpg" alt="" style="max-width: 210px; border-radius: 30px"><br>
         </div>
      </div>
      <div class="row">
         <div class="col-md-10">
            <br>
            <br>
            <br>
            <h3>Lirui (Leroy) Wang</h3> 
            <p> 
               I am a Ph.D. student advised by Prof. <a rel="nofollow" target="_blank" href="http://groups.csail.mit.edu/locomotion/index.html">Russ Tedrake</a> at MIT Computer Science and Artificial Intelligence Laboratory (<a rel="nofollow" target="_blank" href="https://www.csail.mit.edu/">MIT CSAIL</a>). I also work closely with Prof. <a rel="nofollow" target="_blank" href="https://kaiminghe.github.io/">Kaiming He</a>. Before coming to MIT, I received my B.S. and M.S. degrees at <a rel="nofollow" target="_blank" href="https://www.washington.edu/">University of Washington</a> where I was very fortunate to work with Prof. <a rel="nofollow" target="_blank" href="http://homes.cs.washington.edu/~fox/">Dieter Fox</a> and collaborate with <a rel="nofollow" target="_blank" href="https://www.nvidia.com/en-us/">NVIDIA</a>. <br>
            </p><p>
               My research interest lies in Robotics and Machine Learning. In particular, I am interested in developing algorithms and systems for robots that can generalize in the complex and unstructured real-world environments. To achieve this, I work on fleet learning that can scale with the heterogeneous robot data.
            </p><p>
               Email: liruiw [at] mit (dot) edu   
               <a href="https://scholar.google.com/citations?user=EM9YhH0AAAAJ&amp;hl=en">[Google Scholar]</a> / <a href="https://github.com/liruiw">[Github]</a> / <a href="https://twitter.com/LiruiWang1">[Twitter]</a>  / <a href="https://www.linkedin.com/in/lirui-wang/">[LinkedIn]</a> 
            </p>
         </div>
      </div>
      </div>
      <div class="row">
      <div class="col-lg-2">
      </div>

      <div id="education">
      <hr>
         <section class="hero">
           <div class="hero-body">
             <div class="container">
               <ul>
               <h3 class="title is-3">Recent News</h3>
               <div class="content">
               <!--    <li> Our paper on <a rel='nofollow' target='_blank' href='https://liruiw.github.io/hpt'> Heterogeneous Pre-trained Transformer (HPT)</a> is now on arxiv. Check out the <a target='_blank' href='https://github.com/liruiw/HPT-Pretrain'>code</a>, <a target='_blank' href=''>paper</a> and <a target='_blank' href='https://huggingface.co/liruiw/hpt-base'>models</a>!</li>   -->
                  <li> Our paper on <a rel="nofollow" target="_blank" href="https://liruiw.github.io/policycomp">policy composition (PoCo)</a> from and for heterogeneous robot learning has been accepted to RSS 2024.
                  </li><li> Our paper on <a rel="nofollow" target="_blank" href="https://arxiv.org/abs/2310.01361">code generation for robotic simulation</a> won the outstanding paper award at the Language Robotics (LangRob) workshop CoRL 2023 and is accepted by ICLR 2024 as Spotlight. Checkout the <a rel="nofollow" target="_blank" href="https://liruiw.github.io/gensim">website</a>, <a rel="nofollow" target="_blank" href="https://huggingface.co/spaces/Gen-Sim/Gen-Sim">demo</a>, <a rel="nofollow" target="_blank" href="https://chat.openai.com/g/g-rqxeNpjxd-gensim">GPTs</a>, and <a target="_blank" href="https://github.com/liruiw/GenSim">code</a>.  </li>
                <li> Our paper on <a rel="nofollow" target="_blank" href="https://arxiv.org/abs/2310.01362">fleet learning via policy merging</a> is accepted by ICLR 2024. Checkout the <a target="_blank" href="https://github.com/liruiw/Fleet-Tools">code</a>.</li>                   
               </div>
               </ul>
            </div>
            </div>
      <hr>
      <div class="item border-bottom">
         <ul>
            <h3>Publications</h3>
            <div class="container">
  <!--           <table style='border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse' cellspacing='0' bordercolor='#888' border='1'>
                  <tbody>
                     <tr>
                        <td style='width:300px;height:150px'> <a imageanchor='1' href='hpt.gif'><img width='200' id=thumbnail_hpt src='hpt.png' height='140' border='0'  style='border-radius: 5px'/></a></td>
                        <td style='width:1200px;height:89px;padding-left: 10px;'>
                           <b>Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformer</b><br/><b>Lirui Wang</b>, Xinlei Chen, Jialiang Zhao, Kaiming He<br/>on Arxiv, 2024 <br/><a href='https://arxiv.org/abs/2402.02511'>arxiv</a>, <a href='https://github.com/liruiw/HPT-Pretrain'>Code</a>, <a href='liruiw.github.io/hpt'>Website</a>, <a href="javascript:toggle_visibility('wang2024hpt')">Bibtex</a> 
                            <pre id="wang2024hpt" xml:space="preserve" style="display: none; font-size: 12px">
                            @inproceedings{wang2024hpt,
                              author    = {Lirui Wang, Xinlei Chen, Jialiang Zhao, Kaiming He},
                              title     = {Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformer},
                              booktitle = {arXiv:2410.01362},
                              year      = {2024}
                           }
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table>      -->           
            <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="t3.gif"><img width="200" src="images/t3.gif" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>Transferable Tactile Transformers for Representation Learning Across Diverse Sensors and Tasks</b><br>Jialiang Zhao, Yuxiang Ma, <b>Lirui Wang</b>, Edward H. Adelson<br>on Arxiv, 2024 <br><a href="https://arxiv.org/abs/2406.13640">arxiv</a>, <a href="javascript:toggle_visibility('zhao2024t3')">Bibtex</a> , <a href="https://github.com/alanzjl/t3">Code</a>, <a href="https://t3.alanz.info/">Website</a>
                            <pre id="wang2024hpt" xml:space="preserve" style="display: none; font-size: 12px">                            @inproceedings{zhao2024t3,
                              author    = {Lirui Wang, Xinlei Chen, Jialiang Zhao, Kaiming He},
                              title     = {Transferable Tactile Transformers for Representation Learning Across Diverse Sensors and Tasks},
                              booktitle = {arXiv:2406.13640},
                              year      = {2024}
                           }
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table>           
            <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="policycomp.gif"><img width="200" id="thumbnail_poco" src="images/poco_thumbnail.png" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>PoCo: Policy Composition From and For Heterogeneous Robot Learning</b><br><b>Lirui Wang</b>, Jialiang Zhao, Yilun Du, Edward Adelson, Russ Tedrake<br> Robotics: Science and Systems (R:SS), 2024 <br><a href="https://arxiv.org/abs/2402.02511">arxiv</a>, <a href="javascript:toggle_visibility('wang2024poco')">Bibtex</a>, <a href="https://liruiw.github.io/policycomp">Website</a>, <a href="https://www.youtube.com/watch?v=IEulXFl_Th8">Video</a>
                            <pre id="wang2024poco" xml:space="preserve" style="display: none; font-size: 12px">                            @inproceedings{wang2024poco,
                              author    = {Lirui Wang, Jialiang Zhao, Yilun Du, Edward H. Adelson, Russ Tedrake},
                              title     = {Policy Composition From and For Heterogeneous Robot Learning},
                              booktitle = {arXiv:2410.01362},
                              year      = {2024}
                           }
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table> 
               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="fleet_mergin.gif"><img id="thumbnail_fleetmerge" width="200" src="images/fleetmerge_thumbnail.png" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>Robot Fleet Learning via Policy Merging</b><br><b>Lirui Wang</b>, Kaiqing Zhang, Allan Zhou, Max Simchowitz, Russ Tedrake<br>International Conference on Learning Representations (ICLR), 2024<br> <a target="_blank" href="https://arxiv.org/abs/2310.01362">arxiv</a>, <a href="javascript:toggle_visibility('wang2023fleet')">Bibtex</a>, <a target="_blank" href="https://github.com/liruiw/Fleet-Tools">Code</a>, <a target="_blank" href="https://youtu.be/K3fFq91y5FU">Video</a> 
                            <pre id="wang2023fleet" xml:space="preserve" style="display: none; font-size: 12px">                            @article{wang2023fleet,
                             title={Robot Fleet Learning via Policy Merging},
                             author={Wang, Lirui and Zhang, Kaiqing and Zhou, Allan and Simchowitz, Max and Tedrake, Russ},
                             journal={arXiv preprint arXiv:2310.01362},
                             year={2023}
                           }
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table> 


               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="gensim.gif"><img width="200" src="images/gensim.gif" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>GenSim: Generating Robotic Simulation Tasks via Large Language Models</b><br><b>Lirui Wang</b>, Yiyang Ling*, Zhecheng Yuan*, Mohit Shridhar, Chen Bao, Yuzhe Qin, Bailin Wang, Huazhe Xu, Xiaolong Wang<br>Workshop on Language Grounding and Robot Learning (<a style="color: red;">Workshop Best Paper</a>), CoRL 2023 <br>  International Conference on Learning Representations (Spotlight) (ICLR), 2024<br><a target="_blank" href="https://arxiv.org/abs/2310.01361">arXiv</a>, <a target="_blank" href="https://liruiw.github.io/gensim">Website</a>, <a target="_blank" href="https://huggingface.co/spaces/Gen-Sim/Gen-Sim">Demo</a>, <a target="_blank" href="https://github.com/liruiw/GenSim">Code</a>, <a href="https://huggingface.co/Gen-Sim">Dataset</a>, <a href="https://www.youtube.com/watch?v=g-GeqzvkAVY">Video</a>, <a href="https://chat.openai.com/g/g-rqxeNpjxd-gensim">GPTs</a>, <a href="javascript:toggle_visibility('wang2023gensim')">Bibtex</a>
                            <pre id="wang2023gensim" xml:space="preserve" style="display: none; font-size: 12px">                            @inproceedings{wang2023gensim,
                              author    = {Lirui Wang, Yiyang Ling*, Zhecheng Yuan*, Mohit Shridhar, Chen Bao, Yuzhe Qin, Bailin Wang, Huazhe Xu, Xiaolong Wang},
                              title     = {GenSim: Generating Robotic Simulation Tasks via Large Language Models},
                              booktitle = {arXiv:2310.01361},
                              year      = {2023}
                           }
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table> 
               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="dec-ssl2.png"><img width="200" src="images/dec-ssl2.png" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>Does Decentralized Learning with non-IID Unlabeled Data Benefit from Self Supervision?
                           </b><br><b>Lirui Wang</b>, Kaiqing Zhang, Yunzhu Li, Yonglong Tian, and Russ Tedrake<br>International Conference on Learning Representations (ICLR), 2023 <br> <a target="_blank" href="https://arxiv.org/abs/2210.10947">arXiv</a>, <a href="https://github.com/liruiw/Dec-SSL">Code</a>, <a href="javascript:toggle_visibility('wang2022does')">Bibtex</a>, <a href="https://youtu.be/CbSGwsihnEk">Video</a>
                            <pre id="wang2022does" xml:space="preserve" style="display: none; font-size: 12px">                            @inproceedings{wang2022does,
                          title={Does Learning from Decentralized Non-IID Unlabeled Data Benefit from Self Supervision?},
                          author={Wang, Lirui and Zhang, Kaiqing and Li, Yunzhu and Tian, Yonglong and Tedrake, Russ},
                          booktitle={The Eleventh International Conference on Learning Representations},
                          year={2022}
                        }
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table>     
               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="3dnel.gif"><img width="200" src="images/3dnel.gif" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for Robust 6D Pose Estimation</b><br>Guangyao Zhou*, Nishad Gothoskar*, <b>Lirui Wang</b>, Joshua B. Tenenbaum, Dan Gutfreund, Miguel Lázaro-Gredilla, Dileep George, Vikash K. Mansinghka<br>International Conference on Computer Vision (ICCV), 2023 <br> <a target="_blank" href="https://arxiv.org/abs/2302.03744">arXiv</a>, <a target="_blank" href="https://probcomp.github.io/nel/">Website</a>, <a target="_blank" href="https://github.com/deepmind/3dnel">Code</a>, <a href="javascript:toggle_visibility('zhou20233d')">Bibtex</a>
                            <pre id="zhou20233d" xml:space="preserve" style="display: none; font-size: 12px">                            @inproceedings{zhou20233d,
                             title={3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for Robust 6D Pose Estimation},
                             author={Zhou, Guangyao and Gothoskar, Nishad and Wang, Lirui and Tenenbaum, Joshua B and Gutfreund, Dan and L{\'a}zaro-Gredilla, Miguel and George, Dileep and Mansinghka, Vikash K},
                             booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
                             pages={21625--21636},
                             year={2023}
                           }
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table> 

               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="spartn.gif"><img width="200" src="images/spartn.gif" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis
                           </b><br>Allan Zhou*, Moo Jin Kim*, <b>Lirui Wang</b>, Pete Florence, Chelsea Finn<br>The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2023<br> <a target="_blank" href="https://arxiv.org/abs/2301.08556">arxiv</a>, <a target="_blank" href="https://bland.website/spartn/">Website</a>, <a href="javascript:toggle_visibility('zhou2023nerf')">Bibtex</a>
                            <pre id="zhou2023nerf" xml:space="preserve" style="display: none; font-size: 12px">                            @inproceedings{zhou2023nerf,
                                title={Nerf in the palm of your hand: Corrective augmentation for robotics via novel-view synthesis},
                                author={Zhou, Allan and Kim, Moo Jin and Wang, Lirui and Florence, Pete and Finn, Chelsea},
                                booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
                                pages={17907--17917},
                                year={2023}
                              }
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table> 
               
               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="prednet.gif"><img width="200" src="images/prednet.gif" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>PredictionNet: Real-Time Joint Probabilistic Traffic Prediction for Planning, Control, and Simulation
                           </b><br> Alexey Kamenev, <b>Lirui Wang</b>, Ollin Boer Bohan, Ishwar Kulkarni, Bilal Kartal, Artem Molchanov, Stan Birchfield, David Nistér, Nikolai Smolyanskiy <br>International Conference on Robotics and Automation (ICRA), 2022 <br> <a target="_blank" href="https://arxiv.org/abs/2109.11094">arXiv</a>, <a href="javascript:toggle_visibility('kamenev2021predictionnet')">Bibtex</a>, <a href="https://www.youtube.com/watch?v=C7Nb3DRjFP0&amp;t=2s">Video</a>, <a href="https://blogs.nvidia.com/blog/2020/07/22/drive-labs-predictionnet-self-driving-cars-future/">Blog</a>, <a href="https://drive.google.com/file/d/1avqjMojQGseJUqno0obfjhHuW9zFidNc/view?usp=sharing">Poster</a>
                           <pre id="kamenev2021predictionnet" xml:space="preserve" style="display: none; font-size: 12px">                           @inproceedings{kamenev2022predictionnet,
  title={Predictionnet: Real-time joint probabilistic traffic prediction for planning, control, and simulation},
  author={Kamenev, Alexey and Wang, Lirui and Bohan, Ollin Boer and Kulkarni, Ishwar and Kartal, Bilal and Molchanov, Artem and Birchfield, Stan and Nist{\'e}r, David and Smolyanskiy, Nikolai},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={8936--8942},
  year={2022},
  organization={IEEE}
}
                           </pre>
                        </td>
                     </tr>
                  </tbody>
               </table>               
               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="hcg.gif"><img width="200" src="images/hcg.gif" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>Hierarchical Policies for Cluttered-Scene Grasping with Latent Plans
                           </b><br> <b>Lirui Wang</b>, Xiangyun Meng, Yu Xiang, Dieter Fox <br>IEEE Robotics and Automation Letters (RAL), 2022 <br> <a target="_blank" href="https://arxiv.org/abs/2107.01518">arXiv</a>, <a href="javascript:toggle_visibility('wang2021hierarchical')">Bibtex</a>, <a href="https://www.youtube.com/watch?v=9mKfSILbzlg">Video</a>, <a href="https://drive.google.com/file/d/1g6ZsIfOS40_UG6yS9tX_EBOTGdYcl_3c/view?usp=sharing">Poster</a>, <a href="https://sites.google.com/view/latent-grasping">Website</a>, <a href="https://github.com/liruiw/HCG">Code</a> 
                           <pre id="wang2021hierarchical" xml:space="preserve" style="display: none; font-size: 12px">                              @article{wang2022hierarchical,
  title={Hierarchical policies for cluttered-scene grasping with latent plans},
  author={Wang, Lirui and Meng, Xiangyun and Xiang, Yu and Fox, Dieter},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={2},
  pages={2883--2890},
  year={2022},
  publisher={IEEE}
}
                              </pre>
                        </td>
                     </tr>
                  </tbody>
               </table>
               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="gaddpg6.gif"><img width="200" src="images/gaddpg6.gif" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds
                           </b><br> <b>Lirui Wang</b>, Yu Xiang, Wei Yang, Arsalan Mousavian, Dieter Fox <br>The Conference on Robot Learning (CoRL), 2021<br> <a target="_blank" href="https://arxiv.org/abs/2010.00824">arXiv</a>, <a href="javascript:toggle_visibility('wang2020goal')">Bibtex</a>, <a href="https://www.youtube.com/embed/rKsCRXLykiY">Video</a>, <a href="https://drive.google.com/file/d/1ZAzkV_kYL5BFAb5zzvkgI4paDrCPZLoB/view?usp=sharing">Poster</a>, <a href="https://sites.google.com/view/gaddpg">Website</a>, <a href="https://github.com/liruiw/GA-DDPG">Code</a>  
                           <pre id="wang2020goal" xml:space="preserve" style="display: none; font-size: 12px">                                 @inproceedings{wang2022goal,
                                   title={Goal-auxiliary actor-critic for 6d robotic grasping with point clouds},
                                   author={Wang, Lirui and Xiang, Yu and Yang, Wei and Mousavian, Arsalan and Fox, Dieter},
                                   booktitle={Conference on Robot Learning},
                                   pages={70--80},
                                   year={2022},
                                   organization={PMLR}
                                 }
                                 </pre>
                        </td>
                     </tr>
                  </tbody>
               </table>
               <table style="border-width:1px;border-color:rgb(255,255,255);border-collapse:collapse" cellspacing="0" bordercolor="#888" border="1">
                  <tbody>
                     <tr>
                        <td style="width:300px;height:150px"> <a imageanchor="1" href="real_world_omg.gif"><img width="200" src="images/real_world_omg.gif" height="140" border="0" style="border-radius: 5px"></a></td>
                        <td style="width:1200px;height:89px;padding-left: 10px;">
                           <b>Manipulation Trajectory Optimization with Online Grasp Synthesis and Selection</b><br><b>Lirui Wang</b>, Yu Xiang, Dieter Fox<br>Robotics: Science and Systems (R:SS), 2020 <br> <a target="_blank" href="https://arxiv.org/abs/1911.10280">arXiv</a>, <a href="javascript:toggle_visibility('wang2019manipulation')">Bibtex</a>, <a href="https://www.youtube.com/embed/0rZu2cYHzy8">Video</a>, <a href="https://sites.google.com/view/omg-planner">Website</a>, <a href="https://github.com/liruiw/OMG-Planner">Code</a> 
                           <pre id="wang2019manipulation" xml:space="preserve" style="display: none; font-size: 12px">                                 @article{wang2019manipulation,
                                title={Manipulation trajectory optimization with online grasp synthesis and selection},
                                author={Wang, Lirui and Xiang, Yu and Fox, Dieter},
                                journal={arXiv preprint arXiv:1911.10280},
                                year={2019}
                              }
                                 </pre>
                        </td>
                     </tr>
                  </tbody>
               </table>
         </div></ul>
         </div>            
      </section></div>
      <hr>
      <div class="item border-bottom">
         <ul>
            <h3>Education</h3>
            <li> 
               2021.9 - present, Massachusetts Institute of Technology <br>
               Ph.D. student in AI and Decision Making
            </li>            
            <li> 
               2020.6 - 2021.3, University of Washington <br>
               Master of Science in Computer Science 
            </li>
            <li> 
               2016.9 - 2020.6, University of Washington (Summa Cum Laude)   <br>
               Bachelor of Science in Computer Science   <br>
               Bachelor of Science in Electrical Engineering   <br>
               Minor in Mathematics					   
            </li>
         </ul>
      </div>
      <hr>
      <div class="item border-bottom">
         <ul>
            <h3>Selected Honors</h3>
            <li> 
               MIT EECS Fellowship (Xianhong Wu Fellow), MIT, 2021
            </li>
            <li> 
               Bob Herbold Data Science Fellowship, UW, 2021
            </li>
            <li> 
               Patricia  Lynch and Theodora &amp; Eugene Russell Memorial Scholarship, UW, 2020
            </li>
            <li> 
               Lawrence &amp; Lucille Frey Endowed Scholarship, UW, 2019
            </li>
            <li> 
               Tau Beta Pi Scholarship, UW, 2018
            </li>
         </ul>
      </div>
      <hr>
      <div class="item border-bottom">
         <ul>
            <h3>Teaching</h3>
            <li> 
               TA, 6.4210 Robotic Manipulation (MIT, Fall 2022)      
            </li>            
            <li> 
               TA, CSE 455 Computer Vision (UW, Winter 2021)      
            </li>
            <li> 
               TA, CSE 543 Deep Learning (UW, Fall 2020)      
            </li>
            <li> 
               TA, CSE 473 Artificial Intelligence (UW, Winter 2020)     
            </li>
            <li> 
               TA, CSE 455 Computer Vision (UW, Fall 2019)    
            </li>
         </ul>
      </div>
      <hr>
      <div class="item border-bottom">
         <ul>
            <h3>Patent</h3>
            <li> 
               <b>Model-based reinforcement learning for behavior prediction</b> <br>
               Nikolai Smolyanskiy, Alexey Kamenev, <b>Lirui Wang</b>, David Nister, Ollin Boer Bohan, Ishwar Kulkarni, Fangkai Yang, Julia Ng, Alperen Degirmenci, Ruchi Bhargava, Rotem Aviv <br>
               US Patent App. 17/453,055, 2022
            </li>
         </ul>
      </div>
      <hr>
      <div id="education">
         <ul>
         <h3>Misc Projects</h3>
         <table style="float: left; width:30%">

            <tbody><tr>
               <td style="width:801px;height:129px"> <a imageanchor="1" href="deepim.gif"><img width="501" src="images/deepim.gif" height="129" border="100" style="border-radius: 5px"></a></td>
               <td style="width:501px;height:129px"><b>Pose Tracking </b><br>UW <br>   </td>
            </tr>
         </tbody></table>
         <table style="float: left; width:30%">
            <tbody><tr>
               <td style="width:501px;height:129px"> <a imageanchor="1" href="mc_real.gif"><img width="501" src="images/mc_real.gif" height="129" border="0" align="middle" style="border-radius: 5px"></a></td>
               <td style="width:501px;height:129px"><b>Server Mover</b><br>Microsoft<br>
               </td>
            </tr>
   
         </tbody></table>
         <table style="float: left; width:30%">
             <tbody><tr>
               <td style="width:501px;height:129px"> <a imageanchor="1" href="dji_new.gif"><img width="501" src="images/dji_new.gif" height="129" border="0" align="middle" style="border-radius: 5px"></a></td>
               <td style="width:501px;height:129px"><b>Auto Cooperation</b><br>DJI<br>  
<!--                   <a target='_blank' href='https://drive.google.com/file/d/1Dp8NrfpvFx_pqv23bxDlvOGu1g0OIxe4/view'>Demo</a> 
 -->               </td>
            </tr>
         </tbody></table>
      </ul></div>
   
   <br>
   <br>  
</div></div></div></body></html>